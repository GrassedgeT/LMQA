# LMQA è¯„æµ‹æ¨¡å—

æœ¬æ¨¡å—ç”¨äºåœ¨æ ‡å‡†é•¿æ–‡æœ¬QA benchmarkä¸Šè¯„æµ‹LMQAç³»ç»Ÿçš„æ€§èƒ½ã€‚

## ğŸ“‹ æ”¯æŒçš„Benchmark

### 1. LongBench
- **æ¥æº**: https://github.com/THUDM/LongBench
- **æ•°æ®é›†**: åŒ…å«å¤šä¸ªé•¿æ–‡æœ¬ç†è§£ä»»åŠ¡
- **è¯„æµ‹ä»»åŠ¡**:
  - NarrativeQA: å™äº‹é—®ç­”
  - Qasper: ç§‘å­¦è®ºæ–‡é—®ç­”
  - MultiFieldQA: å¤šé¢†åŸŸé—®ç­”
  - HotpotQA: å¤šè·³é—®ç­”
  - 2WikiMultihopQA: ç»´åŸºå¤šè·³é—®ç­”

### 2. LOCOMO (Long Context Multi-hop Reasoning)
- **æ¥æº**: https://github.com/FreedomIntelligence/LOCOMO
- **ç‰¹ç‚¹**: ä¸“æ³¨äºé•¿ä¸Šä¸‹æ–‡å¤šè·³æ¨ç†
- **ä»»åŠ¡ç±»å‹**: éœ€è¦åœ¨é•¿æ–‡æœ¬ä¸­è¿›è¡Œå¤æ‚çš„å¤šæ­¥æ¨ç†

### 3. LooGLE (Long Context Generic Language Evaluation)
- **æ¥æº**: https://github.com/bigai-nlco/LooGLE
- **ä»»åŠ¡**: é•¿æ–‡æ¡£ç†è§£å’Œé—®ç­”

## ğŸ—ï¸ è¯„æµ‹æ¡†æ¶è®¾è®¡

### è¯„æµ‹æµç¨‹

```
1. æ•°æ®åŠ è½½ â†’ 2. ç³»ç»Ÿåˆå§‹åŒ– â†’ 3. æ‰¹é‡æ¨ç† â†’ 4. ç»“æœè¯„ä¼° â†’ 5. æŠ¥å‘Šç”Ÿæˆ
```

### ç›®å½•ç»“æ„

```
evaluation/
â”œâ”€â”€ README.md                 # æœ¬æ–‡ä»¶
â”œâ”€â”€ requirements.txt          # è¯„æµ‹ä¾èµ–
â”œâ”€â”€ config.yaml              # è¯„æµ‹é…ç½®
â”œâ”€â”€ benchmarks/              # Benchmarkæ•°æ®é›†
â”‚   â”œâ”€â”€ longbench/
â”‚   â”œâ”€â”€ locomo/
â”‚   â””â”€â”€ loogle/
â”œâ”€â”€ evaluator.py             # ä¸»è¯„æµ‹å™¨
â”œâ”€â”€ metrics.py               # è¯„æµ‹æŒ‡æ ‡
â”œâ”€â”€ data_loader.py           # æ•°æ®åŠ è½½å™¨
â”œâ”€â”€ results/                 # è¯„æµ‹ç»“æœ
â”‚   â”œâ”€â”€ longbench/
â”‚   â”œâ”€â”€ locomo/
â”‚   â””â”€â”€ reports/
â””â”€â”€ scripts/                 # è¾…åŠ©è„šæœ¬
    â”œâ”€â”€ download_data.py
    â”œâ”€â”€ run_eval.py
    â””â”€â”€ analyze_results.py
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
cd evaluation
pip install -r requirements.txt
```

### 2. ä¸‹è½½æ•°æ®é›†

```bash
# ä¸‹è½½ LongBench
python scripts/download_data.py --benchmark longbench

# ä¸‹è½½ LOCOMO
python scripts/download_data.py --benchmark locomo
```

### 3. é…ç½®è¯„æµ‹

ç¼–è¾‘ `config.yaml` æ–‡ä»¶ï¼Œè®¾ç½®ï¼š
- APIé…ç½®
- è¯„æµ‹æ•°æ®é›†
- é‡‡æ ·ç­–ç•¥
- è¾“å‡ºè·¯å¾„

### 4. è¿è¡Œè¯„æµ‹

```bash
# è¯„æµ‹ LongBench
python scripts/run_eval.py --benchmark longbench --task narrativeqa

# è¯„æµ‹ LOCOMO
python scripts/run_eval.py --benchmark locomo

# è¯„æµ‹æ‰€æœ‰ä»»åŠ¡
python scripts/run_eval.py --all
```

### 5. æŸ¥çœ‹ç»“æœ

```bash
# ç”ŸæˆæŠ¥å‘Š
python scripts/analyze_results.py --result results/longbench/narrativeqa_20260121.json

# æŸ¥çœ‹æ±‡æ€»
cat results/reports/summary.txt
```

## ğŸ“Š è¯„æµ‹æŒ‡æ ‡

### é—®ç­”ä»»åŠ¡æŒ‡æ ‡

1. **F1 Score**: ç­”æ¡ˆä¸å‚è€ƒç­”æ¡ˆçš„è¯æ±‡é‡å åº¦
2. **Exact Match (EM)**: å®Œå…¨åŒ¹é…ç‡
3. **ROUGE-L**: æœ€é•¿å…¬å…±å­åºåˆ—
4. **BLEU**: æœºå™¨ç¿»è¯‘è¯„ä¼°æŒ‡æ ‡
5. **BERTScore**: åŸºäºBERTçš„è¯­ä¹‰ç›¸ä¼¼åº¦

### é•¿æ–‡æœ¬ç‰¹å®šæŒ‡æ ‡

1. **Context Utilization**: ä¸Šä¸‹æ–‡åˆ©ç”¨ç‡
2. **Multi-hop Accuracy**: å¤šè·³æ¨ç†å‡†ç¡®ç‡
3. **Latency**: å“åº”å»¶è¿Ÿ
4. **Memory Efficiency**: å†…å­˜ä½¿ç”¨æ•ˆç‡

## ğŸ”§ é…ç½®è¯´æ˜

### config.yaml ç¤ºä¾‹

```yaml
# ç³»ç»Ÿé…ç½®
system:
  backend_url: "http://localhost:5000"
  api_key: "your-api-key"
  
# è¯„æµ‹é…ç½®
evaluation:
  benchmarks:
    - longbench
    - locomo
  
  # é‡‡æ ·ç­–ç•¥
  sampling:
    max_samples: 100  # æ¯ä¸ªä»»åŠ¡æœ€å¤šè¯„æµ‹100ä¸ªæ ·æœ¬
    random_seed: 42
  
  # è¾“å‡ºé…ç½®
  output:
    save_predictions: true
    save_metrics: true
    result_dir: "results"

# LongBenché…ç½®
longbench:
  tasks:
    - narrativeqa
    - qasper
    - multifieldqa_zh
  data_dir: "benchmarks/longbench"

# LOCOMOé…ç½®
locomo:
  data_dir: "benchmarks/locomo"
  hop_count: [2, 3, 4]  # è¯„æµ‹2è·³ã€3è·³ã€4è·³ä»»åŠ¡
```

## ğŸ“ˆ æ€§èƒ½åŸºå‡†

### LongBenchåŸºå‡†æ€§èƒ½ï¼ˆå‚è€ƒï¼‰

| Model | NarrativeQA | Qasper | MultiFieldQA |
|-------|------------|--------|--------------|
| GPT-4 | 23.6 | 43.3 | 52.3 |
| Claude-2 | 21.0 | 39.7 | 47.6 |
| **LMQA (ç›®æ ‡)** | TBD | TBD | TBD |

### LOCOMOåŸºå‡†æ€§èƒ½ï¼ˆå‚è€ƒï¼‰

| Model | 2-hop | 3-hop | 4-hop | Avg |
|-------|-------|-------|-------|-----|
| GPT-4 | 85.2 | 72.4 | 58.7 | 72.1 |
| **LMQA (ç›®æ ‡)** | TBD | TBD | TBD | TBD |

## ğŸ› ï¸ è‡ªå®šä¹‰è¯„æµ‹

### æ·»åŠ æ–°çš„Benchmark

1. åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼š
```python
# data_loader.py
class CustomBenchmarkLoader(BaseBenchmarkLoader):
    def load(self):
        # å®ç°æ•°æ®åŠ è½½é€»è¾‘
        pass
```

2. æ³¨å†ŒBenchmarkï¼š
```python
# evaluator.py
BENCHMARK_REGISTRY["custom"] = CustomBenchmarkLoader
```

3. æ·»åŠ é…ç½®ï¼š
```yaml
# config.yaml
custom:
  data_dir: "benchmarks/custom"
  # å…¶ä»–é…ç½®...
```

### æ·»åŠ æ–°çš„è¯„æµ‹æŒ‡æ ‡

```python
# metrics.py
@register_metric("custom_metric")
def custom_metric(predictions, references):
    # å®ç°è¯„æµ‹é€»è¾‘
    return score
```

## ğŸ” è¯„æµ‹æœ€ä½³å®è·µ

1. **æ•°æ®é‡‡æ ·**: å»ºè®®å…ˆç”¨å°æ ·æœ¬æµ‹è¯•ï¼Œç¡®è®¤æµç¨‹æ­£å¸¸
2. **æ‰¹é‡å¤„ç†**: ä½¿ç”¨æ‰¹é‡APIå‡å°‘ç½‘ç»œå¼€é”€
3. **é”™è¯¯å¤„ç†**: è®°å½•å¤±è´¥æ¡ˆä¾‹ï¼Œä¾¿äºè°ƒè¯•
4. **ç»“æœä¿å­˜**: ä¿å­˜å®Œæ•´é¢„æµ‹ç»“æœï¼Œä¾¿äºåç»­åˆ†æ
5. **ç‰ˆæœ¬æ§åˆ¶**: è®°å½•æ¨¡å‹ç‰ˆæœ¬å’Œé…ç½®ï¼Œç¡®ä¿å¯å¤ç°

## ğŸ“ è¯„æµ‹æŠ¥å‘Šç¤ºä¾‹

```
============================================
LMQA Evaluation Report
============================================
Date: 2026-01-21
Model: LMQA v1.0
Benchmark: LongBench

--------------------------------------------
NarrativeQA Results
--------------------------------------------
Total Samples: 100
F1 Score: 24.5
Exact Match: 15.2
ROUGE-L: 28.3
Average Latency: 2.3s

--------------------------------------------
Error Analysis
--------------------------------------------
Failed Samples: 3
Common Errors:
  - Context retrieval failure: 2
  - API timeout: 1

============================================
```

## ğŸ› æ•…éšœæ’é™¤

### é—®é¢˜1: æ•°æ®ä¸‹è½½å¤±è´¥
```bash
# æ‰‹åŠ¨ä¸‹è½½æ•°æ®é›†å¹¶è§£å‹åˆ° benchmarks/ ç›®å½•
wget https://github.com/THUDM/LongBench/releases/download/v1.0/data.zip
unzip data.zip -d benchmarks/longbench/
```

### é—®é¢˜2: APIè¿æ¥è¶…æ—¶
- æ£€æŸ¥backendæœåŠ¡æ˜¯å¦è¿è¡Œ
- å¢åŠ timeouté…ç½®
- ä½¿ç”¨é‡è¯•æœºåˆ¶

### é—®é¢˜3: å†…å­˜ä¸è¶³
- å‡å°‘batch_size
- ä½¿ç”¨æµå¼å¤„ç†
- é™åˆ¶max_samples

## ğŸ“š å‚è€ƒèµ„æº

- [LongBench Paper](https://arxiv.org/abs/2308.14508)
- [LOCOMO GitHub](https://github.com/FreedomIntelligence/LOCOMO)
- [LooGLE Paper](https://arxiv.org/abs/2311.04939)

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®æ–°çš„benchmarkæ”¯æŒæˆ–è¯„æµ‹æŒ‡æ ‡ï¼è¯·æäº¤PRå¹¶ç¡®ä¿ï¼š
- ä»£ç é€šè¿‡æµ‹è¯•
- æ·»åŠ ç›¸å…³æ–‡æ¡£
- æ›´æ–°README

---

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥é˜…æ–‡æ¡£æˆ–æäº¤Issueã€‚
